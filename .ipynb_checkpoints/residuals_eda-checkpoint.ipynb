{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cross_validation import *\n",
    "from gradient_boost import predict_xgboost\n",
    "from read_write import read_merged_data, load_pickled_model\n",
    "from plotting_functions import scatter_plot_eda\n",
    "from helper import add_rolling_averages\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "def get_finite_residual(df):\n",
    "    return df[pd.notnull(df.Residual)]\n",
    "\n",
    "def add_exponential_smoothing(df, dictionary):\n",
    "    for key, value in dictionary.iteritems():\n",
    "        for window in value:\n",
    "            # Name of new feature\n",
    "            name = 'Last' + str(window) + 'ExponentialSmoothingAverage' + key\n",
    "\n",
    "            # Drop column to prevent duplicates\n",
    "            if name in df.columns:\n",
    "                df.pop(name)\n",
    "\n",
    "            # Get exponential smoothing rolling average\n",
    "            df[name] = pd.ewma(df[key], halflife = window).shift(1)\n",
    "\n",
    "def add_residuals(df, element):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        df -- DataFrame\n",
    "        element -- string of element we are getting residuals for\n",
    "    Output:\n",
    "        DataFrame with residuals column added\n",
    "    \"\"\"\n",
    "    # Load model\n",
    "    m = load_pickled_model('{}GradientBoostedRegressor'.format(element))\n",
    "    \n",
    "    # Predict\n",
    "    predictions, filtered_df = predict_xgboost(df, \n",
    "                                               element = element, \n",
    "                                               data_info = data_info)\n",
    "\n",
    "    prediction_df = pd.DataFrame()\n",
    "    prediction_df['Predicted{}'.format(element)] = predictions\n",
    "    prediction_df['Player'] = filtered_df.Player\n",
    "    prediction_df['Date'] = filtered_df.Date\n",
    "    prediction_df['Team'] = filtered_df.Team\n",
    "    return df.merge(prediction_df, on = ['Player', 'Date', 'Team'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('data/merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filtering info\n",
    "data_info = cv_method(method = k_folds_cv,\n",
    "                      splits = 5,\n",
    "                      start_date = '1999-01-01',\n",
    "                      end_date = '2016-09-01',\n",
    "                      minutes_cutoff = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Examine data\n",
    "# \"\"\"\n",
    "# 1. There is a duplicate season column\n",
    "# \"\"\"\n",
    "# print \"Num rows: {}\".format(len(df))\n",
    "# for column in df.columns:\n",
    "#     print column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268913\n",
      "268913\n"
     ]
    }
   ],
   "source": [
    "# Add residuals\n",
    "df = add_residuals(df, 'FanDuelScore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              NaN\n",
       "1         4.625285\n",
       "2         4.080391\n",
       "3              NaN\n",
       "4         5.088479\n",
       "5              NaN\n",
       "6         4.080391\n",
       "7              NaN\n",
       "8         5.151088\n",
       "9         5.151088\n",
       "10        4.060582\n",
       "11             NaN\n",
       "12             NaN\n",
       "13        5.151088\n",
       "14             NaN\n",
       "15             NaN\n",
       "16        6.228477\n",
       "17        6.228477\n",
       "18             NaN\n",
       "19        6.590546\n",
       "20        5.151088\n",
       "21             NaN\n",
       "22             NaN\n",
       "23        4.060582\n",
       "24             NaN\n",
       "25        5.151088\n",
       "26        6.228477\n",
       "27        6.228477\n",
       "28             NaN\n",
       "29        6.590546\n",
       "            ...   \n",
       "393565    3.991554\n",
       "393566    4.830759\n",
       "393567    4.623190\n",
       "393568    4.165205\n",
       "393569    5.427077\n",
       "393570    5.471296\n",
       "393571    6.172874\n",
       "393572         NaN\n",
       "393573    4.322453\n",
       "393574    5.975366\n",
       "393575    4.670088\n",
       "393576    6.037975\n",
       "393577    5.064297\n",
       "393578    4.694627\n",
       "393579    4.528644\n",
       "393580    4.416434\n",
       "393581    5.164608\n",
       "393582    3.879365\n",
       "393583         NaN\n",
       "393584         NaN\n",
       "393585         NaN\n",
       "393586    6.908555\n",
       "393587         NaN\n",
       "393588    4.033860\n",
       "393589    5.581286\n",
       "393590    4.249230\n",
       "393591    5.373204\n",
       "393592    6.415595\n",
       "393593         NaN\n",
       "393594    4.456901\n",
       "Name: PredictedFanDuelScore, dtype: float32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore features to predict residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_df = align_players(filtered_df)\n",
    "print len(filtered_df)\n",
    "\n",
    "# Display DataFrame\n",
    "filtered_df[pd.notnull(filtered_df.StarterLineupOrder)].loc[:,['Player_x','StarterLineupOrder', 'Residual_x', 'BucketedMinutes_x', 'Player_y', 'BucketedMinutes_y', 'Residual_y']]\n",
    "\n",
    "# Remove all rows with NaN for 'Residual_y'\n",
    "filtered_df.dropna(subset = ['PlayerDefenseMatchupResidual'], inplace = True, axis = 0)\n",
    "print len(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Experimentation shows that 30.85 is the optimal half-life decay parameter for predicting 'Residual_y'\n",
    "# based on the exponential smoothing of \n",
    "\n",
    "player_exponential_smoothing_dict = {'PlayerDefenseMatchupResidual': [30.80,30.85,30.90]}\n",
    "def add_position_defense_stats(df):\n",
    "    # Remove all rows with NaN for 'Residual_y'\n",
    "    filtered_df = df.dropna(subset = ['PlayerDefenseMatchupResidual'], axis = 0)\n",
    "    filtered_df = filtered_df.groupby(['Player']).apply(GB_apply_player_position)\n",
    "    return filtered_df\n",
    "filtered_df = add_position_defense_stats(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key, value in player_exponential_smoothing_dict.iteritems():\n",
    "    for window in value:\n",
    "        scatter_plot_eda(filtered_df, key + 'ExponentialSmoothing' + str(window), 'PlayerDefenseMatchupResidual', 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = filtered_df.groupby(['Date', 'Team', 'Frontcourt']).aggregate(np.sum)\n",
    "f.reset_index(level=['Team', 'Date', 'Frontcourt'], inplace=True)\n",
    "for key, value in player_exponential_smoothing_dict.iteritems():\n",
    "    for window in value:\n",
    "        old_name = key + 'ExponentialSmoothing' + str(window)\n",
    "        rename_dict = {old_name : 'PositionGroup' + old_name}\n",
    "        f.rename(columns = rename_dict, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['PositionGroup'+ key + 'ExponentialSmoothing' + str(window) for window in value for key, value in player_exponential_smoothing_dict.iteritems()]\n",
    "features += ['Date', 'Team', 'Frontcourt']\n",
    "filtered_df = filtered_df.merge(f[features], on = ['Date', 'Team', 'Frontcourt'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key, value in player_exponential_smoothing_dict.iteritems():\n",
    "    for window in value:\n",
    "        scatter_plot_eda(filtered_df, 'PositionGroup' + key + 'ExponentialSmoothing' + str(window), 'PlayerDefenseMatchupResidual', 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = [key + 'ExponentialSmoothing' + str(window) for window in value for key, value in player_exponential_smoothing_dict.iteritems()]\n",
    "features += ['PlayerDefenseMatchup', 'Date', 'Team']\n",
    "df = df.merge(filtered_df[features], left_on = ['Player', 'Date', 'Opp'], right_on = ['PlayerDefenseMatchup', 'Date', 'Team'], how = 'left')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
